%!TEX root = ../../lod-group1.tex
\subsection{Matching}
\label{subsec_evaluation_matching}

\subsubsection{Introduction}
The matching algorithm, explained in \ref{subsec_method_matching}, depends on multiple parameters.
The following paragraphs explain the process of tuning these parameters and evaluating the quality of the matching algorithm.

Evaluation is done on two sets of 4000 randomly selected movies.
The selection is done by listing all movies by name and then using $scala.util.Random$ to shuffle the list and take the first 4000 movies.
The first list is used for the parameter opitimization, while the second is used for the final evaluation purpose.
To get a gold standard only those movies with an annotated IMDb-id are taken into concideration.
However, the id is not used to match the movies.
These movies can be split into two parts: the movies that could potentially be matched and the movies that can not be matched, i.e. movies that do not exist in the database.
The result is a list of 3300 TODO movies the algorithm is tested with.
2008 of these movies could possibly be matched.

Given the set of new movies N and the set of existing movies M the following function calculates the correct matching movie $m_{j} \in M$ of a new movie $n_{i} \in N$:

\begin{align}
	gold: ~&N \rightarrow M \cup \{\bot\} \\
	gold(n) &=
		\begin{cases}
		m \in M ~\text{if matching movie m exists in database}  \\
		\bot
		\end{cases}
\end{align}

Using this function and the algorithm $match_{n_{i}}$ explained in \ref{subsec_method_matching} the following sets are defined:

\begin{description}
\item[True Positives (TP)] is the set of correct matches between a new movie and an existing one in the database,
\begin{align}
TP &\coloneqq \Set*{(n_i, match(n_i))}{match(n_i) = gold(n_i) \land match(n_i) \neq \bot}
\end{align}
\item[False Positives (FP)] is the set of incorrect matches, either meaning another movie is the correct match or no correct match exists in the database
\begin{align}
FP &\coloneqq \Set*{(n_i, match(n_i))}{match(n_i) \neq gold(n_i) \land match(n_i) \neq \bot}
\end{align}\item[True Negatives (TN)] is the set of tuples that are no matches and that cannot be matched because they are not in the database,
\begin{align}
FP &\coloneqq \Set*{(n_i, m_j)}{m_j \in M \land (m_j \neq match(n_i) \land m_j \neq gold(n_i) \lor m_j = \bot)}
\end{align}
\item[False Negatives (FN)] is the set of correct matches between movies that have not been found.
\begin{align}
FP &\coloneqq \Set*{(n_i, m_j)}{m_j \in M \land m_j \neq match(n_i) \land m_j = gold(n_i) \land m_j \neq \bot}
\end{align}
\end{description}

Based on these sets the standard evaluation measures \emph{Precision (P)}, \emph{Recall (R)}, and \emph{F-measure} are calculated.
As explained in Section \ref{subsec_method_matching}, Precision is more important and therefore the F0.5-measure is additionally observed in the evaluation process.

To generate consistent result, the whole evaluation is done without the distributed enviroment, as explained in Chap. \ref{subsec_method_architecture}, but on a single machine with the following system specifications:
\begin{itemize}
\item CPU: Pentium(R) Dual-Core  CPU E5300  @ 2.60GHz
\item RAM: RAM: 16GB
\item OS: Debian 3.2.57
\end{itemize}

The evaluation process in structures into two parts. First multiple evaluation steps are conducted to find the optimal values for the possible parameters in the process. Therefore, the first test looks at the impact on the quality of the results when the number of considered candidates is lowered. A second test observes the maximum Levenshtein distance between two actors and the threshold that needs to be reached for the actor overlap. The Levenshtein distance of the candidates is regared in the third test. Finally, the algorithm will be evaluated on the second dataset against the baseline approach of matching by name. Thereby each annotated name of the movie is compared with each name of all the movies in the database.

what is evaluated TODO
list of annotated properties

\subsubsection{Candidate Parameter}
\subsubsection{Threshold Parameter}
\subsubsection{Refinement Weight}
\subsubsection{Comparison to Baseline Approach}